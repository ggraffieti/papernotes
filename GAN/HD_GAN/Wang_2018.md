[[project](https://tcwang0509.github.io/pix2pixHD/)] [[paper](https://arxiv.org/abs/1711.11585)] [[code](https://github.com/NVIDIA/pix2pixHD)] [[video](https://www.youtube.com/watch?v=3AIpPlzM_qs&feature=youtu.be)]

Inserted:\
Last revision:

# High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs
**Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Andrew Tao, Jan Kautz, Bryan Catanzaro**
<br>
<br>
Novel method to generate high resolution images that are realistic and can be edited at inference time.

Three main contributions:
1. a novel adversarial loss.
2. a new multiscale generator and discriminator architecture
3. object instance segmentation information included in the model (mainly for label-to-image mapping).

### Coarse to fine generator
- The generator G is decomposed into two sub-networks: G<sub>1</sub> and G<sub>2</sub>. G<sub>1</sub> is trained as the global generator, and G<sub>2</sub> as the local enhancer network. G<sub>1</sub> operates at image size of 1024x512 while G<sub>2</sub> works with a 4x resolution (2x along each axis).
- The global generator G<sub>1</sub> is the same as pix2pix or cycleGAN ([Johnson _et al._ architecture](https://arxiv.org/abs/1603.08155)). It can be further divided in three components: a convolutional frontend G<sub>1</sub><sup>F</sup>, a set of residual blocks G<sub>1</sub><sup>R</sup>, and a convolutional backend G<sub>1</sub><sup>B</sup>. The same division can be done for G<sub>2</sub>.
- The input of G<sub>2</sub><sup>R</sup> is the element-wise sum of two feature maps: the output feature vector of G<sub>2</sub><sup>F</sup> and the last feature map of G<sub>1</sub><sup>B</sup>.

<p align="center">
<img src="img/wang2018_model.png"
</p>

First, the network G<sub>1</sub> is trained alone, and then the local enhancer(s) are trained in the order of their resolution (more than one enhancer network could be present). I.e. when G<sub>2</sub> is trained, the weight of G<sub>1</sub> are not updated. At the end of the training of each network, all the networks are fine-tuned together.

### Multiscale discriminator
- High resolution image synthesis posed a significant challenge in GAN discriminator design, since working with high resolution (thus very high dimensional data) means that the discriminator has to have a large receptive field. But a large receptive field is prone to concentrate only on large structures of the image, and not on the details.
- The authors proposed a multi-scale discriminator with three different discriminators at different image scales. The real and synthesized images are downsampled by a factor of 2 and 4, in order to create an image pyramid of three scales.
- The discriminator that operates at the coarsest scale has the largest receptive field (the three discriminators have the same architecture, but smaller images &rarr; more portion of the image in the receptive field). The discriminator that operates at the coarsest size has a more global view of the image, and can guide the generator to output globally consistent images (e.g. global shapes of objects). On the other hand, the discriminator that operates at the finest scale encourage the generation of finer details (e.g. sharper borders, small details).
- Without multi-discriminator many repeated patterns are often observed in the generated images.
